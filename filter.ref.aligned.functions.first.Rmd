---
title: "Aph.rad.filtering"
author: "Devon DeRaad"
date: "9/17/2020"
output: html_document
---

```{r setup}
library(vcfR)
library(ggplot2)
library(gridExtra)
library(ggridges)
library(adegenet)
```

#RADStacksHelpR
```{r define functions}
#do hard filtering with this function:
hard.filter.vcf <- function(vcfR, depth=NULL, gq=NULL){
  
  #extract depth from the vcf
  dp.matrix<- extract.gt(vcfR, element='DP', as.numeric=TRUE)
  
  #calculate the SNPs that fall below the depth filter
  i<-round((sum(dp.matrix < depth, na.rm = TRUE)/sum(!is.na(dp.matrix)))*100, 2)
  #report filter
  print(paste0(i,"% of genotypes fall below a read depth of ",depth," and were converted to NA"))
  
  #convert to NAs
  dp.matrix[dp.matrix < depth] <- NA
  vcfR@gt[,-1][ is.na(dp.matrix) == TRUE ] <- NA
  
  #extract gq from the vcf
  gq.matrix<- extract.gt(vcfR, element='GQ', as.numeric=TRUE)
  
  #calculate the SNPs that fall below the gq filter
  j<-round((sum(gq.matrix < gq, na.rm = TRUE)/sum(!is.na(gq.matrix)))*100, 2)
  #report filter
  print(paste0(j,"% of genotypes fall below a genotype quality of ",gq," and were converted to NA"))
  
  #convert to NAs
  gq.matrix[gq.matrix < gq] <- NA
  vcfR@gt[,-1][ is.na(gq.matrix) == TRUE ] <- NA
  
  return(vcfR)
}

filter.allele.balance <- function(vcfR){
  
  #extract AD from the vcf
  ad.matrix<- extract.gt(vcfR, element='AD')
  #extract GT from the vcf
  gt.matrix<- extract.gt(vcfR, element='GT')
  
  #mask dp matrix to include only called hets from gt matrix
  ad.matrix[gt.matrix != "0/1"]<-NA
  
  #split allele 1 depth from allele 2 depth
  al1<-structure(as.numeric(gsub(",.*", "", ad.matrix)), dim=dim(ad.matrix))
  al2<-structure(as.numeric(gsub(".*,", "", ad.matrix)), dim=dim(ad.matrix))
  
  #calculate percentage of hets failing AB filter
  AB<-al1/(al1 + al2) > .75 | al1/(al1 + al2) <.25
  p<-round(sum(AB, na.rm = TRUE) / sum(is.na(AB) == FALSE)*100, 2)
  j<-round(sum(AB, na.rm = TRUE) / sum(is.na(gt.matrix) == FALSE)*100, 2)
  
  print(paste0(p,"% of het genotypes (",j,"% of all genotypes) fall outside of .25 - .75 allele balance and were converted to NA"))
  
  #convert failing genotypes to NA
  vcfR@gt[,-1][AB]<-NA
  
  return(vcfR)
}

#function to vis and filter by maximum depth
max.depth <- function(vcfR, maxdepth=NULL){
  
  #extract depth from the vcf
  dp.matrix<- extract.gt(vcfR, element='DP', as.numeric=TRUE)
  
  #calculate vector of depth per SNP
  snpdepth<-rowSums(dp.matrix, na.rm = TRUE)/rowSums(is.na(dp.matrix) == FALSE)
    if (is.null(maxdepth)){

    #plot histogram of depth
    hist(snpdepth, xlab = "mean of the depth of all samples successfully genotyped at a given SNP", main =NULL)
    abline(v=mean(snpdepth, na.rm = TRUE), col="red", lty="dashed")
    
    #zoomed in histogram
    hist(snpdepth[snpdepth < 200], xlab = "mean of the depth of all samples successfully genotyped at a given SNP", main ="visualize distribution of SNPs below a depth of 200")
    abline(v=mean(snpdepth, na.rm = TRUE), col="red", lty="dashed")
    
    #print
    print(paste0("dashed line indicates a mean depth across all SNPs of ",round(mean(snpdepth, na.rm = TRUE),1)))

    }
  
      else {
      #plot the maxdepth cutoff
      hist(snpdepth, xlab = "mean of the depth of all samples successfully genotyped at a given SNP", main ="max depth cutoff")
      abline(v=maxdepth, col="red")
      
      #calculate % of snps that fail the max depth filter
      i<-round(sum(snpdepth > maxdepth, na.rm = TRUE)/length(snpdepth)*100, 2)

      print(paste0(i, "% of SNPs were above a mean depth of ", maxdepth, " and were removed from the vcf"))
      
      #filter vcf
      vcfR<-vcfR[snpdepth < maxdepth,]
      
      return(vcfR)
    }
}

#define function to visualize missing data
missing.by.sample <- function(vcfR, popmap=NULL, cutoff=NULL){
        
  #extract depth from the vcf
  dp<- extract.gt(vcfR, element='DP', as.numeric=TRUE)
  
        if (is.null(cutoff)){

            if (is.null(popmap)) {
                print("No popmap provided")
                } 
            else {
                #calculate missingness by pop here and make dotplot
                  #popmap must be a two column dataframe with 'id' and 'pop' columns
                  #id's must match the ids in the vcf file
                  #calculate missingness by individual
                  miss<-colSums(is.na(dp))/nrow(dp)
                  #calculate avg depth by individual
                  avg.depth<-colMeans(dp, na.rm = TRUE)
                  #store ordered column names
                  samples<-colnames(dp)
                  #create df
                  df.x<-data.frame(id=samples,missingness=miss,avg.depth=avg.depth, row.names = NULL)
                  #bring in popmap
                  df.f<-merge(df.x, popmap, by="id")
                  #plot missingness and depth by pop
                  plot1<-ggplot(df.f, aes(x= reorder(pop, -missingness), y=missingness)) + 
                    geom_violin()+ theme_classic()+
                    theme(axis.title.x = element_blank(), axis.text.x = element_text(angle = 60, hjust = 1))+
                    ylab("proportion missing")+
                    geom_dotplot(binaxis='y', stackdir='center', dotsize=.8)
                  #dotplot avg depth of sequencing       
                  plot2<-ggplot(df.f, aes(x= reorder(pop, -missingness), y=avg.depth)) + 
                    geom_violin()+ theme_classic()+
                    theme(axis.title.x = element_blank(), axis.text.x = element_text(angle = 60, hjust = 1))+
                    ylab("average depth")+
                    geom_dotplot(binaxis='y', stackdir='center', dotsize=.8)
                  
                  #
                  grid.arrange(plot1,plot2)
                  
                }
      

    #initialize dataframe
    df.y<- data.frame(indiv=character(), snps.retained=numeric(), filt=numeric())
    #loop
    for (i in c(.5,.6,.7,.8,.9,1)){
      #get vector of individuals we are looping over
      indiv<-colnames(dp)
      #calculate the completeness cutoff for each snp to be retained in this iteration
      filt<-rep(i, times =ncol(dp))
      #calculate the number of loci successfully genotyped in each sample in this iteration
      snps.retained<-colSums(is.na(dp[(rowSums(is.na(dp))/ncol(dp) <= 1-i),]) == "FALSE")
      #append the data from this iteration to existing df
      df.y<-rbind(df.y, as.data.frame(cbind(indiv, filt, snps.retained)))
      #close for loop
    }
    
    #make columns numeric for plotting
    df.y$filt<-as.numeric(as.character(df.y$filt))
    df.y$snps.retained<-as.numeric(as.character(df.y$snps.retained))
    #visualize color coded by individual
    print( 
      ggplot(df.y, aes(x=filt, y=snps.retained, color=indiv))+
        geom_point()+
        ggtitle("SNPs retained by filtering scheme") +
        xlab("fraction of non-missing genotypes required to retain each SNP (0-1)") + ylab("non-missing SNPs retained per sample")+
        theme_light()+
        theme(legend.position="none")
    )
    
    #calculate missingness by individual
    miss<-colSums(is.na(dp))/nrow(dp)
    #show plot with missingness by sample
    dotchart(sort(miss), cex=.5, xlab = "proportion missing data")
    abline(v=c(.5,.6,.7,.8,.9,1), lty="dashed")
    
    #return the dataframe showing the missingness and avg depth per individual
    return(df.x)
    
      }
  else {
    
    #calculate missingness by individual
    miss<-colSums(is.na(dp))/nrow(dp)
    #vis plot to show where cutoff was set
    dotchart(sort(miss), cex=.5)
    abline(v=cutoff, col="red")
    
    #print
    print(paste0(length(labels(miss)[miss > cutoff])," samples fall below ",cutoff," missing data cutoff, and were removed from VCF"))
    #drop those individuals from vcfR
    vcfR@gt <- vcfR@gt[,!(colnames(vcfR@gt) %in% labels(miss)[miss > cutoff])]

    return(vcfR)
  }
    
}

#define function
missing.by.snp <- function(vcfR, cutoff=NULL){
  
  if (!is.null(cutoff)) {
    
    #do basic vis to show cutoff
    #extract genotype from the vcf
    dp.matrix<- extract.gt(vcfR, as.numeric=TRUE)

    #calculate the proportion of individuals successfully genotyped at each SNP
    miss<-rowSums(is.na(dp.matrix))/ncol(dp.matrix)
    
    #loop that stores a vector of # non-missing loci retained for each individual
    #looped over all possible completeness filter values
    #initialize df.x
    df.x<- data.frame(filt=numeric(), missingness=numeric(), snps.retained=numeric())
    #loop
    for (i in c(.3,.5,.6,.65,.7,.75,.8,.85,.9,.95,1)){
      #subset the matrix to only snps passing a given filter level
      gen.z.mat<-dp.matrix[1-miss >= i,]
      #calc the total number of snps retained at the given filter level
      snps.retained<-nrow(gen.z.mat)
      #calculate the total missing data % for the given cutoff
      missingness<-sum(is.na(gen.z.mat))/(ncol(gen.z.mat)*nrow(gen.z.mat))
      #calculate the completeness cutoff for each snp to be retained
      filt<-i
      df.x<-rbind(df.x, as.data.frame(cbind(filt, missingness, snps.retained)))
      }
    
    #make columns numeric for plotting
    df.x$filt<-as.numeric(as.character(df.x$filt))
    df.x$missingness<-as.numeric(as.character(df.x$missingness))
    df.x$snps.retained<-as.numeric(as.character(df.x$snps.retained))
    
    #visualize dotplot for total loci retained at each filter level
    plot1<-ggplot(df.x, aes(x=filt)) +
      scale_x_continuous(breaks=c(.3,.5,.6,.65,.7,.75,.8,.85,.9,.95,1))+
      geom_point(aes(y=snps.retained)) +
      theme_bw() +
      labs(x = "SNP completeness cutoff", y = "total loci retained")+
      geom_vline(xintercept = cutoff, color = "red")
    
    #visualize dotplot for missing data % at each filter level
    plot2<-ggplot(df.x, aes(x=filt)) +
      scale_x_continuous(breaks=c(.3,.5,.6,.65,.7,.75,.8,.85,.9,.95,1))+
      geom_point(aes(y=missingness)) +
      theme_bw() +
      labs(x = "SNP completeness cutoff", y = "total % missing data")+
      geom_vline(xintercept = cutoff, color = "red")
    
    grid.arrange(plot1,plot2)
    
    #calc # of SNPs filtered
    p<-round(sum(miss > 1-cutoff)/length(miss)*100, 2)
    
    #report # of SNPs filtered
    print(paste0(p,"% of SNPs fell below a completeness cutoff of ", cutoff, " and were removed from the VCF"))
    
    #do filtering
    vcfR <- vcfR[miss <= 1-cutoff, ]
    
    return(vcfR)
    
  } 
  else {
    
    ###Part 1
    #Vis to understand the interplay between retaining samples and setting a missing data cutoff
    #extract genotype from the vcf
    dp.matrix<- extract.gt(vcfR, as.numeric=TRUE)
    
    #calculate vector containing the proportion of individuals successfully genotyped at each SNP
    miss<-rowSums(is.na(dp.matrix))/ncol(dp.matrix)
    #initialize df.x
    df.y<- data.frame(filt=numeric(), snps=numeric())
    #loop
    for (i in c(.3,.5,.6,.65,.7,.75,.8,.85,.9,.95,1)){
      #subset matrix to only SNPs retained at given filter level
      gen.z.mat<-dp.matrix[1-miss >= i,]
      #calc the total number of snps retained at the given filter level in each sample
      snps<-colSums(is.na(gen.z.mat) == TRUE)/nrow(gen.z.mat)
      #calculate the completeness cutoff for each snp to be retained
      filt<-rep(i, times= length(snps))
      df.y<-rbind(df.y, as.data.frame(cbind(filt, snps)))
      }
    
    #make columns numeric for plotting
    df.y$filt<-as.numeric(as.character(df.y$filt))
    df.y$snps<-as.numeric(as.character(df.y$snps))
    
    #visualize filtering levels as stacked histograms
    print(
      ggplot(df.y, aes(x = snps, y = as.character(filt), fill = filt, color = filt)) +
        geom_density_ridges(jittered_points = TRUE, position = "raincloud", alpha = .25, cex=.5) +
        theme_classic() +
        labs(x = "missing data proportion in each sample", y = "SNP completeness cutoff") +
        theme(legend.position = "none")
      )
    
    ###Part 2
    #Vis to make decision on cutoff
    #calculate the proportion of individuals successfully genotyped at each SNP
    miss<-rowSums(is.na(dp.matrix))/ncol(dp.matrix)
    
    #loop that stores a vector of # non-missing loci retained for each individual
    #looped over all possible completeness filter values
    #initialize df.x
    df.x<- data.frame(filt=numeric(), missingness=numeric(), snps.retained=numeric())
    #loop
    for (i in c(.3,.5,.6,.65,.7,.75,.8,.85,.9,.95,1)){
      #subset the matrix to only snps passing a given filter level
      gen.z.mat<-dp.matrix[1-miss >= i,]
      #calc the total number of snps retained at the given filter level
      snps.retained<-nrow(gen.z.mat)
      #calculate the total missing data % for the given cutoff
      missingness<-sum(is.na(gen.z.mat))/(ncol(gen.z.mat)*nrow(gen.z.mat))
      #calculate the completeness cutoff for each snp to be retained
      filt<-i
      df.x<-rbind(df.x, as.data.frame(cbind(filt, missingness, snps.retained)))
      }
    
    #make columns numeric for plotting
    df.x$filt<-as.numeric(as.character(df.x$filt))
    df.x$missingness<-as.numeric(as.character(df.x$missingness))
    df.x$snps.retained<-as.numeric(as.character(df.x$snps.retained))
    
    #visualize dotplot for total loci retained at each filter level
    plot1<-ggplot(df.x, aes(x=filt)) +
      scale_x_continuous(breaks=c(.3,.5,.6,.65,.7,.75,.8,.85,.9,.95,1))+
      geom_point(aes(y=snps.retained)) +
      theme_bw() +
      labs(x = "SNP completeness cutoff", y = "total loci retained")

    #visualize dotplot for missing data % at each filter level
    plot2<-ggplot(df.x, aes(x=filt)) +
      scale_x_continuous(breaks=c(.3,.5,.6,.65,.7,.75,.8,.85,.9,.95,1))+
      geom_point(aes(y=missingness)) +
      theme_bw() +
      labs(x = "SNP completeness cutoff", y = "total proportion missing data")

    grid.arrange(plot1,plot2)
  }
  
}

#define function
min.mac <- function(vcfR, popmap=NULL, min.mac=NULL){
  
  if (is.null(min.mac)) {
    
    #convert vcfR to matrix and make numeric  
    gt.matrix<-extract.gt(vcfR)
    gt.matrix[gt.matrix == "0/0"]<-0
    gt.matrix[gt.matrix == "0/1"]<-1
    gt.matrix[gt.matrix == "1/1"]<-2
    class(gt.matrix) <- "numeric"
    
    #calc sfs
    sfs<-rowSums(gt.matrix, na.rm = TRUE)
    #fold sfs
    for (i in 1:length(sfs)) {
      if (sfs[i] <= sum(!is.na(gt.matrix[i,]))){}
      else {
        sfs[i]<-(sum(!is.na(gt.matrix[i,]))*2 - sfs[i])
      }
    }
    
    #hist folded mac with cutoff shown
    hist(sfs, main="folded SFS", xlab = "MAC")
    
    #convert vcfR into genlight
    genlight<-vcfR2genlight(vcfR)

    #run dapc for mac 1,2,3,4,5,10
    for (i in c(1,2,3,4,5,10)){
      
      #filter genlight by given mac
      genlight<-genlight[,sfs >= i]
      #subset sfs vector to only samples left in the vcf
      sfs<-sfs[sfs >= i]
      
      #assign samples to the number of groups present in popmap, retain all PCAs
      grp<-find.clusters(genlight, n.pca = ncol(gt.matrix)-1, n.clust = length(levels(popmap$pop)))
      
      #check how well that assignment matched up to the provided popmap
      samps<-merge(popmap, data.frame(group=grp$grp, id=labels(grp$grp)), by='id')
      print(paste0("for ", i, " minimum MAC cutoff, compare k means clustering to popmap assignment"))
      print(table(samps$pop, samps$group))
      
      #run dapc, retain all discriminant axes, and enough PC axes to explain 75% of variance
      dapc1<-dapc(genlight, grp$grp, n.da = length(levels(popmap$pop))-1, pca.select = "percVar", perc.pca = 75)
      
      #plot compoplot
      compoplot(dapc1, legend=FALSE, col=funky(length(levels(popmap$pop))), show.lab =TRUE, cex.names=.4, main=paste0("min. MAC ",i,", total SNPs ",length(sfs)))
      
      #print
      print(paste0("DAPC with min. MAC ", i, " and ", length(sfs), " total SNPs, complete"))
    }
    
  } 
    else {
      
    #convert vcfR to matrix and make numeric  
    gt.matrix<-extract.gt(vcfR)
    gt.matrix[gt.matrix == "0/0"]<-0
    gt.matrix[gt.matrix == "0/1"]<-1
    gt.matrix[gt.matrix == "1/1"]<-2
    class(gt.matrix) <- "numeric"
    
    #calc sfs
    sfs<-rowSums(gt.matrix, na.rm = TRUE)
    #fold sfs
    for (i in 1:length(sfs)) {
      if (sfs[i] <= sum(!is.na(gt.matrix[i,]))){}
      else {
        sfs[i]<-(sum(!is.na(gt.matrix[i,]))*2 - sfs[i])
      }
    }
    
    #hist folded mac with cutoff shown
    hist(sfs, main="folded SFS", xlab = "MAC")
    abline(v=min.mac-1, col="red")
    
    #calculate % of SNPs to be removed, and print it
    p<-round((sum(sfs < min.mac)/length(sfs))*100, 2)
    print(paste0(p, "% of SNPs fell below a minor allele count of ", min.mac, " and were removed from the VCF"))
    
    #filter vcfR
    vcfR <- vcfR[sfs >= min.mac,]
    
    return(vcfR)

    }
  
}
```

Read in your unfiltered vcf file
```{r}
#read in vcf as vcfR
vcfR <- read.vcfR("~/Desktop/aph.data/populations.snps.vcf")
### check the metadata present in your vcf
vcfR
vcfR@fix[1:10,1:8]
vcfR@gt[1:10,1:2]

#generate popmap file. Two column popmap with the same format as stacks, and the columns must be named 'id' and 'pop'
#popmap<-data.frame(id=colnames(vcfR@gt)[2:length(colnames(vcfR@gt))],pop=substr(colnames(vcfR@gt)[2:length(colnames(vcfR@gt))], 3,11))
#read in locality info for samples
locs<-read.csv("~/Desktop/aph.data/rad.sampling.csv")
popmap<-data.frame(id=locs$id, pop=locs$species)
#rename mislabeled sample
colnames(vcfR@gt)[colnames(vcfR@gt) == "A_californica_334171"]<-"A_woodhouseii_334171"
```

#step 1: Implement quality filters that don't involve missing data. This is because removing low data samples will alter percentage/quantile based missing data cutoffs, so we wait to implement those until after deciding on our final set of samples for downstream analysis
Note:If you have a very large vcf output file that you would like to work with in Rstudio, you could implement some percentage based filters (e.g. remove all SNPs above 50% missing data) via vcftools to reduce your filesize before starting to filter in R. Just be aware that once you drop low data samples, your previously enforced (per SNP or locus) missing data % will no longer be exact.

Jon Puritz has an excellent filtering tutorial that is focused specifically on filtering RADseq data: https://www.ddocent.com/filtering/
Some of these RAD specific filters can't be applied to a vcf output by stacks, which doesn't retain metadata like mapping quality and strand, but we can follow these guidelines for hard filtering (he suggests minimum depth=3, gq =30), and can implement suggested filters like allele balance and max depth, here in R.
```{r}
#hard filter to minimum depth of 5, and minimum genotype quality of 30
vcfR<-hard.filter.vcf(vcfR=vcfR, depth = 3, gq = 30)
```

Use this function to filter for allele balance
from Puritz SNP filtering tutorial "Allele balance: a number between 0 and 1 representing the ratio of reads showing the reference allele to all reads, considering only reads from individuals called as heterozygous, we expect that the allele balance in our data (for real loci) should be close to 0.5"
```{r}
#execute allele balance filter
vcfR<-filter.allele.balance(vcfR)
```

max depth filter (super high depth loci are likely multiple loci stuck together into a single paralogous locus).
Note: we want to apply this 'per SNP' rather than 'per genotype' otherwise we will simply be removing most of the genotypes from our deepest sequenced samples (because sequencing depth is so variable between samples)
```{r}
#visualize and pick appropriate max depth cutoff
max.depth(vcfR)

#filter vcf by the max depth cutoff you chose
vcfR<-max.depth(vcfR, maxdepth = 100)
```


Note: It may be a good idea to additionally filter out SNPs that are significantly out of HWE if you have a really good idea of what the population structure in your sample looks like and good sample sizes in each pop. For this dataset, which is highly structured (many isolated island pops) with species boundaries that are in flux, I am not going to use a HWE filter, because I don't feel comfortable confidently identifying populations in which we can expect HWE.

```{r}
#check vcfR to see how many SNPs we have left
vcfR
```

#Step 2: visualize missing data by sample. Check out the visualizations and make decision on which samples to keep for downstream analysis.

Determining which samples to retain is highly project specific, and is contingent on your sampling, your taxa, the sequencing results, etc.
It is also wise to take missing data into account by population. Often we don't know a-priori what our populations will look like, but in general we want to avoid making inferences about populations if they have consistently less information than the rest of our dataset.
On the flip side of that coin, you may have designed a project to get information about a rare sample/population that lacks existing genetic sampling, and therefore must retain specific samples despite low sequencing and high missing data. This is a reality, and simply needs to be addressed carefully.
```{r}
#run function to visualize samples
missing.by.sample(vcfR=vcfR, popmap = popmap)

#run function to drop samples above the threshold we want from the vcf
vcfR<-missing.by.sample(vcfR=vcfR, cutoff = .93)

#subset popmap to only include retained individuals
popmap<-popmap[popmap$id %in% colnames(vcfR@gt),]

#alternatively, you can drop individuals from vcfR manually using the following syntax, if a strict cutoff doesn't work for your dataset
#vcfR@gt <- vcfR@gt[,colnames(vcfR@gt) != "E_trichroa_4702" & colnames(vcfR@gt) != "E_trichroa_27882"]
```


#Step 3: Set the arbitrary missing data cutoff
We can visualize the effect that typical missing data cutoffs will have on both the number of SNPs retained and the total missing data in our entire dataset.
We want to choose a cutoff that minimizes the overall missing data in the dataset, while maximizing the total number of loci retained.
Note: This will also depend on the samples that we decided to include above. A good rule of thumb is that samples shouldn't be above 50% missing data after applying this cutoff. So if we are retaining low data samples out of necessity or project design, we may have to set a more stringent cutoff at the expense of total SNPs retained for downstream analyses.
```{r}
#visualize missing data by SNP and the effect of various cutoffs on the missingness of each sample
missing.by.snp(vcfR)
#choose a value that retains an acceptable amount of missing data in each sample, and maximizes SNPs retained while minimizing overall missing data, and filter vcf
vcfR<-missing.by.snp(vcfR, cutoff = .85)
```


#Step 4: investigate the effect of a minor allele frequency cutoff on our downstream inferences. 
MAF cutoffs can be helpful in removing spurious and uninformative loci from the dataset, but also have the potential to bias downstream inferences. Linck and Battey (2019) have an excellent paper on just this topic. From the paper-

"We recommend researchers using model‐based programs to describe population structure observe the following best practices:
(a) duplicate analyses with nonparametric methods suchas PCA and DAPC with cross validation
(b) exclude singletons
(c) compare alignments with multiple assembly parameters
When seeking to exclude only singletons in alignments with missing data (a ubiquitous problem for reduced‐representation library preparation methods), it is preferable to filter by the count (rather than frequency) of the minor allele, because variation in the amount of missing data across an alignment will cause a static frequency cutoff to remove different SFS classes at different sites""

Our package contains a convenient wrapper functions that streamline the investigation of different MAF cutoffs.
Warning: this is a heavy function if it is run without the 'min.mac' option. It is converting the entire vcf and running 6 unique dapc iterations, which will take time for large datasets. If you set 'min.mac' it will just filter your dataset, and should run quickly.
```{r}
#use min.mac() to investigate the effect of multiple cutoffs
min.mac(vcfR = vcfR, popmap = popmap)

#based on these visualizations, I will remove singletons from the dataset, as it doesn't affect group inference
vcfR<-min.mac(vcfR, min.mac = 2)
```

check once more to see how many SNPs and individuals remain compared to our original, unfiltered vcf
```{r}
vcfR

#plot depth per snp and per sample
dp <- extract.gt(vcfR, element = "DP", as.numeric=TRUE)
heatmap.bp(dp, rlabels = FALSE)

#plot genotype quality per snp and per sample
gq <- extract.gt(vcfR, element = "GQ", as.numeric=TRUE)
heatmap.bp(gq, rlabels = FALSE)

```

We can use the convenient function 'write.vcf' from vcfR to export our filtered vcf file for downstream analyses
```{r}
#write.vcf(vcfR, "~/Desktop/aph.data/filtered.vcf.gz")
```

If you need physically unlinked loci (which is a requirement of some programs, e.g. structure) this filtering step should always be done last, because it is not quality aware. Introducing a quality-blind linkage filter before doing the quality based filtering shown here would potentially remove quality SNPs while leaving us with only the low quality SNPs in a locus or genomic region.
If filtering for linkage is needed, it can be done on our output vcf file with a simple one-liner via vcftools (set thin to whatever bp distance you assume linakge decays at in your study organism)
vcftools --vcf vcf.vcf --thin 10000 --recode --out vcf
